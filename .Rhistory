samsize <- array(numeric(nr*np), dim=c (nr,np))
for (i in 1:np){
for (j in 1:nr){
result <- pwr.r.test(n = NULL, r=r[j], sig.level = .05, power = p[i],
alternative = "two.sided")
samsize[j,i] <- ceiling(result$n)
}
}
# 创建图形
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",xlab="Correlation Coefficient (r)", ylab="Sample Size (n)" )
# 添加功效曲线
for (i in 1:np){
lines(r, samsize[,i],type="l",lwd=2, col=colors[i])
}
# 添加网格线
abline(v=O, h=seq(0, yrange[2],50), lty=2, col="grey89")
# 生成一系列相关系数和功效值
library (pwr)
r <- seq(.1, .5,.01)
nr <- length(r)
p <- seq(.4,.9,.1)
np <- length(p)
# 获取样本大小
samsize <- array(numeric(nr*np), dim=c (nr,np))
for (i in 1:np){
for (j in 1:nr){
result <- pwr.r.test(n = NULL, r=r[j], sig.level = .05, power = p[i],
alternative = "two.sided")
samsize[j,i] <- ceiling(result$n)
}
}
# 创建图形
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",xlab="Correlation Coefficient (r)", ylab="Sample Size (n)" )
# 添加功效曲线
for (i in 1:np){
lines(r, samsize[,i],type="l",lwd=2, col=colors[i])
}
# 添加网格线
abline(v=0, h=seq(0, yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange [1],xrange [2],.02), lty=2, col="gray89")
# 添加注释
title("Sample Size Estimation for Correlation Studies\nSig=0.05 (Two-tailed)")
legend("topright", title="Power", as.character(p),fill=colors)
install.packages('coin')
install.packages('lmPerm')
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
library(coin)
score <- с(40, 57, 45, 55, 58, 57, 64, 55, 62, 65)
library(coin)
score <- c(40, 57, 45, 55, 58, 57, 64, 55, 62, 65)
treatment <- factor(c(rep("A",5), rep("B",5)))
mydata <- data.frame(treatment, score)
t.test(score~treatment, data=mydata, var.equal=TRUE)
oneway_test(score~treatment, data=mydata, distribution="exact")
library(MASS)
UScrime <- transform(UScrime, So = factor(So))
wilcox_test(Prob ~ So, data=UScrime, distribution="exact")
library(multcomp)
set.seed(1234)
oneway_test(response~trt, data=cholesterol,distribution=approximate(B=9999))
library(coin)
library(vcd)
Arthritis <- transform(Arthritis,Improved=as.factor(as.numeric(Improved)))
set.seed(1234)
chisq_test(Treatment~Improved, data=Arthritis,distribution=approximate(B=9999))
states <- as.data.frame(state.x77)
set.seed(1234)
spearman_test(Illiteracy~Murder, dataestates,distribution=approximate(B=9999))
states <- as.data.frame(state.x77)
set.seed(1234)
spearman_test(Illiteracy~Murder, data=states,distribution=approximate(B=9999))
library(coin)
library(MASS)
wilcoxsign_test(U1~U2, data=UScrime, distribution="exact")
library (lmPerm)
set.seed (1234)
fit1 <- lmp(weight~height, data=women, perm="Prob")
summary(fit1)
library(lmPerm)
set.seed (1234)
fit2 <- lmp (weight~height + I(height^2), data=women, perm="Prob")
summary(fit2)
library(lmPerm)
set.seed(1234)
states <- as.data.frame(state.x77)
fit3 <- lmp(Murder~Population + Illiteracy + Income + Frost, data=states, perm="Prob")
summary(fit3)
library(lmPerm)
library(multcomp)
set.seed(1234)
fit4 <- aovp(response~trt, data=cholesterol, perm="Prob")
anova(fit4)
library(lmPerm)
set.seed(1234)
fit5 <- aovp(weight ~ gesttime + dose, data=litter, perm="Prob")
anova(fit5)
library(lmPerm)
set.seed(1234)
fit6 <- aovp(len~supp*dose, data=ToothGrowth, perme="Prob")
anova(fit6)
install.packages('boot')
library(boot)
set.seed(1234)
results <- boot(data=mtcars, statistic=rsq,R=1000, formula=mpg~wt+disp)
rsq <- function(formula, data, indices){
d <- data[indices, ]
fit <- lm(formula, data=d)
return(summary(fit)$r.square)
}
library(boot)
set.seed(1234)
results <- boot(data=mtcars, statistic=rsq,R=1000, formula=mpg~wt+disp)
# boot的对象可以输出
print(results)
plot(results)
boot.ci(results, type=c("perc", "bca"))
bs <- function(formula, data, indices){
d <- data[indices, ]
fit <- lm(formula, data=d)
return(coef(fit))
}
# 然后使用该函数自助抽样1000次
library(boot)
set.seed(1234)
results <- boot(data=mtcars, statistic=bs,R=1000, formula=mpg~wt+disp)
print(results)
plot(results, index=2)
boot.ci(results, type="bca", index=2)
boot.ci(results, type="bca", index=2)
boot.ci(results, type="bca", index=3)
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
plot(predict(model,type="response"), residuals (model,type="deviance"))
install.packages("AER")
library(AER)
data(Affairs)
summary(Affairs)
library(AER)
data(Affairs)
summary(Affairs)
table(Affairs$affairs)
Affairs$ynaffair[Affairs$affairs > 0] <- 1
Affairs$ynaffair[Affairs$affairs ==0] <- 0
Affairs$ynaffair <- factor(Affairs$ynaffair,levels=c(0,1),labels=c("No","Yes"))
table(Affairs$ynaffair)
fit.full <- glm(ynaffair ~ gender + age + yearsmarried + children + religiousness +
education + occupation + rating, data=Affairs,family=binomial())
summary(fit.full)
fit.reduced <- glm(ynaffair ~ age + yearsmarried + religiousness + rating,data=Affairs,family=binomial())
summary(fit.reduced)
anova(fit.reduced,fit.full,test="Chisq")
coef(fit.reduced)
exp(coef(fit.reduced))
testdata <- data.frame(rating=c(1,2,3,4,5),age=mean(Affairs$age),
yearsmarried=mean (Affairs$yearsmarried),religiousness=mean(Affairs$religiousness))
testdata
testdata$prob <- predict(fit.reduced,newdata=testdata,type="response")
testdata
testdata <- data.frame(rating=mean(Affairs$rating),
age=seg(17,57,10),yearsmarried=mean(Affairs$yearsmarried),
religiousness=mean(Affairs$religiousness))
testdata <- data.frame(rating=mean(Affairs$rating),
age=seq(17,57,10),yearsmarried=mean(Affairs$yearsmarried),
religiousness=mean(Affairs$religiousness))
testdata
testdata <- data.frame(rating=mean(Affairs$rating),
age=seq(17,57,10),yearsmarried=mean(Affairs$yearsmarried),
religiousness=mean(Affairs$religiousness))
testdata
testdata$prob <- predict(fit.reduced,newdata=testdata,type="response")
testdata
deviance(fit.reduced)/df.residual(fit.reduced)
pchisq(summary(fit.od)$dispersion * fitsdf.residual, fit$df.residual,lower = F)
fit1 <-glm(ynaffair ~ age yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
fit1 <-glm(ynaffair ~ age yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
fit <- glm(ynaffair ~ age yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
deviance(fit.reduced)/df.residual(fit.reduced)
fit <- glm(ynaffair ~ age yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
fit <- glm(ynaffair ~ age + yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
fit.od <- glm(ynaffair ~ age + yearsmarried + religiousness + rating,
family = quasibinomial(),data = Affairs)
pchisq(summary(fit.od)$dispersion * fitsdf.residual,fit$df.residual,lower = F)
fit <- glm(ynaffair ~ age + yearsmarried + religiousness + rating,family = binomial(),data = Affairs)
fit.od <- glm(ynaffair ~ age + yearsmarried + religiousness + rating,
family = quasibinomial(),data = Affairs)
pchisq(summary(fit.od)$dispersion * fit$df.residual,fit$df.residual,lower = F)
install.packages('robust')
data(breslow.dat,package="robust")
names(breslow.dat)
data(breslow.dat,package="robust")
names(breslow.dat)
summary(breslow.dat[c(6,7,8,10)]
data(breslow.dat,package="robust")
names(breslow.dat)
summary(breslow.dat[c(6,7,8,10)])
opar <- par(no.readonly=TRUE)
par(mfrow=c(1,2))
attach(breslow.dat)
hist(sumY,breaks=20,xlab="Seizure Count",main="Distribution of Seizures")
boxplot(sumY ~ Trt,xlab="Treatment",main="Group Comparisons")
par(opar)
fit1 <-glm(sumY ~ Base + Age + Trt,data=breslow.dat,family=poisson())
summary(fit1)
coef(fit1)
exp(coef(fit1))
deviance(fit1)/df.residual(fit1)
install.packages('qcc')
library(qcc)
qcc.overdispersion.test(breslow.datssumy,type="poisson")
library(qcc)
qcc.overdispersion.test(breslow.dat$sumy,type="poisson")
library(qcc)
qcc.overdispersion.test(breslow.dat$sumY,type="poisson")
fit.od <- glm(sumY ~ Base + Age + Trt,data=breslow.dat,family=quasipoisson())
summary(fit.od)
install.packages('psych')
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
library(psych)
fa.parallel(USJudgeRatings[,-1],fa="pc",n.iter=100,
show.legend=FALSE,main="Scree plot with parallel analysis")
library(psych)
pc <- principal(USJudgeRatings[,-1],nfactors=1)
pc
library(psych)
pc <- principal(USJudgeRatings[,-1],nfactors=1)
head(pc)
library(psych)
pc <- principal(USJudgeRatings[,-1],nfactors=1)
pc
library(psych)
fa.parallel(Harman23.corscov,n.obs=302,fa="pc",n.iter=100,show.legend=FALSE,main="Scree plot with parallel analysis")
library(psych)
fa.parallel(Harman23.cor$cov,n.obs=302,fa="pc",n.iter=100,show.legend=FALSE,main="Scree plot with parallel analysis")
library(psych)
pc1 <- principal(USJudgeRatings[,-1],nfactors=1)
pc1
library(psych)
pc2 <-principal(Harman23.cor$cov,nfactors=2,rotate="none")
pc2
rc1 <-principal(Harman23.cor$cov,nfactors=2,rotate="varimax")
rc1
library(psych)
pc2 <- principal(USJudgeRatings[,-1],nfactors=1,score=TRUE)
head(pc$scores)
cor(USJudgeRating$SCONT,pc2$score)
cor(USJudgeRatings$CONT,pc2$score)
library(psych)
rc2 <- principal(Harman23.cor$cov,nfactors=2,rotate="varimax")
round(unclass(rc2$weights),2)
PC1 = 0.28*height + 0.30*arm.span + 0.30*forearm + 0.29*lower.leg -
0.06*weight - 0.08*bitro.diameter - 0.10*chest.girth - 0.04*chest.width
options(digits=2)
covariances <- ability.covscov
options(digits=2)
covariances <- ability.cov$cov
correlations <- cov2cor(covariances)
correlations
library(psych)
covariances <- ability.covscov
library(psych)
covariances <- ability.cov$cov
correlations <- cov2cor(covariances)
fa.parallel(correlations,n.obs=112,fa="both",n.iter=100,
main="Scree plots with parallel analysis")
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
library(psych)
fa.parallel(USJudgeRatings[,-1],fa="pc",n.iter=100,
show.legend=FALSE,main="Scree plot with parallel analysis")
library(psych)
pc1 <- principal(USJudgeRatings[,-1],nfactors=1)
pc1
library(psych)
fa.parallel(Harman23.cor$cov,n.obs=302,fa="pc",n.iter=100,show.legend=FALSE,main="Scree plot with parallel analysis")
library(psych)
pc2 <-principal(Harman23.cor$cov,nfactors=2,rotate="none")
pc2
rc1 <-principal(Harman23.cor$cov,nfactors=2,rotate="varimax")
rc1
library(psych)
pc2 <- principal(USJudgeRatings[,-1],nfactors=1,score=TRUE)
head(pc2$scores)
cor(USJudgeRatings$CONT,pc2$score)
library(psych)
rc2 <- principal(Harman23.cor$cov,nfactors=2,rotate="varimax")
round(unclass(rc2$weights),2)
options(digits=2)
covariances <- ability.cov$cov
correlations <- cov2cor(covariances)
correlations
fa <-fa(correlations,nfactors=2,rotate="none",fm="pa")
fa
fa.varimax <- fa(correlations,nfactors=2,rotate="varimax",fm="pa")
fa.varimax
fa.promax <- fa(correlations,nfactors=2,rotate="promax",fm="pa")
fa.promax <- fa(correlations,nfactors=2,rotate="promax",fm="pa")
fa.varimax <- fa(correlations,nfactors=2,rotate="varimax",fm="pa")
fa.varimax
fa.promax <- fa(correlations,nfactors=2,rotate="promax",fm="pa")
install.packages('GPArotation')
fa.promax <- fa(correlations,nfactors=2,rotate="promax",fm="pa")
fa.promax
fsm <-function (oblique){
if (class(oblique)[2]=="fa" & is.null(oblique$Phi)){
warning("Object doesn't look like oblique EFA")
} else {
P <- unclass(oblique$loading)
F <- P %*% oblique$Phi
colnames(F) <- c("PA1","PA2")
return(F)
}
}
fsm(fa.promax)
factor.plot(fa.promax,labels=rownames(fa.promax$loadings))
fa.diagram(fa.promax,simple=FALSE)
library(psych)
fa.24tests <- fa(Harman74.corscov,nfactors=4,rotate="promax")
library(psych)
fa.24tests <- fa(Harman74.cor$cov,nfactors=4,rotate="promax")
fa.promax$weights
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
# 生成时序对象
sales <- c(18,33,41,7,34,35,24,25,24,21,25,20,22,31,40,29,25,21,22,54,31,25,26,35)
tsales <- ts(sales,start=c(2003,1),frequency=12)
tsales
# 生成时序对象
sales <- c(18,33,41,7,34,35,24,25,24,21,25,20,22,31,40,29,25,21,22,54,31,25,26,35)
tsales <- ts(sales,start=c(2003,1),frequency=12)
tsales
# 获得这个对象的信息
plot(tsales)
start(tsales)
end(tsales)
frequency(tsales)
# 对对象取子集
tsales.subset <- window(tsales,start=c(2003,5),end=c(2004,6))
tsales.subset
install.packages('forecast')
library(forecast)
library(forecast)
library(forecast)
install.packages("forecast")
library(forecast)
library(forecast)
library(forecast)
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
library(forecast)
library(forecast)
knitr::opts_chunk$set(prompt=TRUE,comment='',echo=TRUE,collapse=TRUE,message=FALSE,warning=FALSE)
pkgs <-c("rpart","rpart.plot","party", "randomForest","e1071")
install.packages(pkgs,depend=TRUE)
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "breast-cancer-wisconsin/breast-cancer-wisconsin.data"
url <- paste(loc,ds,sep="")
breast <- read.table(url,sep=",",header=FALSE,na.strings="?")
names(breast) <- c("ID","clumpThickness","sizeUniformity","shapeUniformity","maginalAdhesion",
"singleEpithelialCellsize","bareNuclei","blandchromatin","normalNucleoli",
"mitosis","class")
df <- breast[-1]
df$class <- factor(df$class,levels=c(2,4),labels=c("benign","malignant"))
set.seed(1234)
train <- sample(nrow(df),0.7*nrow(df))
df.train <- df[train,]
df.validate <- df[-train,]
table(df.train$class)
table(df.validate$class)
# 拟合逻辑回归
fit.logit <- glm(class~.,data=df.train,family=binomial())
summary(fit.logit)
# 拟合逻辑回归
fit.logit <- glm(class~.,data=df.train,family=binomial())
# 检查模型
summary(fit.logit)
# 对训练集集外样本单元分类
prob <- predict(fit.logit,df.validate,type="response")
logit.pred <- factor(prob >.5,levels=c(FALSE,TRUE),labels=c("benign","malignant"))
# 评估预测准确性
logit.perf <- table(df.validatesclass,logit.pred,dnn=c("Actual","Predicted"))
# 拟合逻辑回归
fit.logit <- glm(class~.,data=df.train,family=binomial())
# 检查模型
summary(fit.logit)
# 对训练集集外样本单元分类
prob <- predict(fit.logit,df.validate,type="response")
logit.pred <- factor(prob >.5,levels=c(FALSE,TRUE),labels=c("benign","malignant"))
# 评估预测准确性
logit.perf <- table(df.validate$class,logit.pred,dnn=c("Actual","Predicted"))
logit.perf
# 生成树
library(rpart)
set.seed(1234)
dtree <- rpart(class ~.data=df.train,method="class",parms=list(split="information"))
# 生成树
library(rpart)
set.seed(1234)
dtree <- rpart(class ~.,data=df.train,method="class",parms=list(split="information"))
dtree$cptable
# 生成树
library(rpart)
set.seed(1234)
dtree <- rpart(class ~.,data=df.train,method="class",parms=list(split="information"))
dtree$cptable
plotcp(dtree)
# 剪枝
dtree.pruned <- prune(dtree,cp=.0125)
library(rpart.plot)
prp(dtree.pruned,type = 2,extra = 104,fallen.leaves = TRUE,main="Decision Tree")
# 生成树
library(rpart)
set.seed(1234)
dtree <- rpart(class ~.,data=df.train,method="class",parms=list(split="information"))
dtree$cptable
plotcp(dtree)
# 剪枝
dtree.pruned <- prune(dtree,cp=.0125)
library(rpart.plot)
prp(dtree.pruned,type = 2,extra = 104,fallen.leaves = TRUE,main="Decision Tree")
# 对训练集外样本单元分类
dtree.pred <- predict(dtree.pruned,df.validate,type="class")
dtree.perf <- table(df.validate$class,dtree.pred,dnn=c("Actual","Predicted"))
dtree.perf
library(party)
fit.ctree <- ctree(class~.,data=df.train)
plot(fit.ctree,main="Conditional Inference Tree")
ctree.pred <- predict(fit.ctree,df.validate,type="response")
ctree.perf <- table(df.validate$class,ctree.pred,dnn=c("Actual","Predicted"))
ctree.perf
install.packages('partykit')
# 生成森林
library(randomForest)
set.seed(1234)
fit.forest <- randomForest(class~.,data=df.train,na.action=na.roughfix, importance=TRUE)
fit.forest
# 生成森林
library(randomForest)
set.seed(1234)
fit.forest <- randomForest(class~.,data=df.train,na.action=na.roughfix, importance=TRUE)
fit.forest
# 给出变量重要性
importance(fit.forest,type=2)
# 对训练集外样本点分类
forest.pred <- predict(fit.forest,df.validate)
forest.perf <- table(df.validate$class,forest.pred,dnn=c("Actual","Predicted"))
forest.perf
library(e1071)
set.seed(1234)
fit.svm <- svm(class~.,data=df.train)
fit.svm
svm.pred <- predict(fit.svm,na.omit(df.validate))
svm.perf <- table(na.omit (df.validate)$class,svm.pred,dnn=c("Actual","Predicted"))
svm.perf
# 变换参数
set.seed(1234)
tuned <- tune.svm(class~.,data=df.train,gamma=10^(-6:1),cost=10^(-10:10))
tuned # 输出最优模型
# 用这些参数拟合模型
fit.svm <- svm(class~.,data=df.train,gamma=.01,cost=1)
# 评估交叉验证表现
svm.pred <- predict(fit.svm,na.omit(df.validate))
svm.perf <- table(na.omit(df.validate)$class,svm.pred,dnn=c("Actual","Predicted"))
svm.perf
performance <- function(table,n=2){
if(!all(dim(table)==c(2,2)))
stop("Must be a 2 x 2 table")
tn = table[1,1]
fp = table[1,2]
fn = table[2,1]
tp = table[2,2]
sensitivity = tp/(tp+fn)
specificity = tn/(tn+fp)
ppp = tp/(tp+fp)
npp = tn/(tn+fn)
hitrate = (tp+tn)/(tp+tn+fp+fn)
result <- paste("Sensitivity =", round(sensitivity,n),"\nSpecificity = ",round(specificity,n),
"InPositive Predictive value = ", round(ppp,n),
"\nNegative Predictive Value = ", round(npp,n),
"\nAccuracy = ", round(hitrate,n),"\n",sep="")
cat(result)
}
performance(logit.perf)
performance(logit.perf)
performance(dtree.perf)
performance(ctree.perf)
performance(forest.perf)
performance(logit.perf)
performance(dtree.perf)
performance(ctree.perf)
performance(forest.perf)
performance(svm.perf)
install.packages('rattle')
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "pima-indians-diabetes/pima-indians-diabetes.data"
url <- paste(loc,ds,sep="")
diabetes <- read.table(url,sep=",",header=FALSE)
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "pima-indians-diabetes/pima-indians-diabetes.data"
url <- paste(loc,ds,sep="")
diabetes <- read.table(url,sep=",",header=FALSE)
library(rattle)
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "pima-indians-diabetes/pima-indians-diabetes.data"
url <- paste(loc,ds,sep="")
diabetes <- read.table(url,sep=",",header=FALSE)
library(rattle)
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
ds <- "pima-indians-diabetes/pima-indians-diabetes.data"
url <- paste(loc,ds,sep="")
diabetes <- read.table(url,sep=",",header=FALSE)
